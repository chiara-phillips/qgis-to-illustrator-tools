{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f439266e-7706-4a77-aceb-a8e5d45650bb",
   "metadata": {},
   "source": [
    "# üåä **Clipping North Atlantic Ocean by Latitude Bands**\n",
    "\n",
    "This notebook prepares the **North Atlantic Ocean** geometry for **zonal analysis** by clipping it into latitude-based regions. We use global latitude bands to divide the ocean into horizontal slices (e.g., 30¬∞N‚Äì40¬∞N), then calculate daily chlorophyll-a concentration trends within each slice.\n",
    "\n",
    "The workflow includes:\n",
    "- Loading the **GOaS ocean boundaries** and **latitude band** datasets.\n",
    "- Clipping the **North Atlantic** region by each latitude band.\n",
    "- Extracting **daily chlorophyll values** per band from a NetCDF raster.\n",
    "- Exporting a time series of chlorophyll means and generating plots.\n",
    "\n",
    "## üìë Table of Contents\n",
    "- [üß∞ 1. Import Required Libraries](#1-import-required-libraries)  \n",
    "- [üåä 2. Load Ocean Vector (GOaS)](#2-load-ocean-vector-goas)  \n",
    "- [üó∫Ô∏è 3. Load Latitude Bands](#3-load-latitude-bands)  \n",
    "- [‚úÇÔ∏è 4. Clip Ocean by Latitude](#4-clip-ocean-by-latitude)  \n",
    "- [üìà 5. Extract Chlorophyll Data](#5-extract-chlorophyll-data)  \n",
    "- [üìä 6. Visualize Time Series](#6-visualize-time-series)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0fcb665-2c67-4e91-a2f2-49f8aefaa293",
   "metadata": {},
   "source": [
    "## üß∞ **1. Import Required Libraries**\n",
    "\n",
    "- **Geospatial libraries**  \n",
    "  For working with map data like polygons and raster files:  \n",
    "  - `geopandas` loads and manipulates vector data (e.g., shapefiles, GeoJSON).  \n",
    "  - `shapely` helps define and clean up geometric shapes.  \n",
    "  - `rasterio` and `rioxarray` let us read and clip NetCDF raster files (like chlorophyll data).  \n",
    "\n",
    "- **Data handling and computation**  \n",
    "  For loading, cleaning, and processing data efficiently:  \n",
    "  - `pandas` handles tabular data.  \n",
    "  - `numpy`, `xarray`, and `dask` allow large, multi-dimensional data processing in chunks.  \n",
    "\n",
    "- **Plotting libraries**  \n",
    "  To visualize chlorophyll concentrations and trends:  \n",
    "  - `matplotlib.pyplot` draws plots and maps.  \n",
    "  - `matplotlib.dates` formats date-based x-axes.  \n",
    "  - `matplotlib.cm` provides access to color palettes.  \n",
    "\n",
    "- **Utilities**  \n",
    "  For smooth workflows and progress tracking:  \n",
    "  - `tqdm` shows progress bars in loops.  \n",
    "  - `pathlib` handles file paths across systems.  \n",
    "  - `re` helps clean up and format text (like band labels).\n",
    "  - `loguru` displays clean and colorful logging messages (e.g., üéâ success, üö© error)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65ce0912-8a2f-4fa6-b56b-a8dffa628c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Geospatial libraries ---\n",
    "import geopandas as gpd  # Geographic vector data (GeoDataFrames)\n",
    "from shapely.geometry import Polygon  # Creating polygon geometries\n",
    "import rasterio  # Raster file I/O and metadata\n",
    "import rasterio.mask  # Masking raster data with geometries\n",
    "import rioxarray as rxr  # Geospatial extension for xarray (CRS-aware raster I/O)\n",
    "\n",
    "# --- Data handling and computation ---\n",
    "import pandas as pd  # Tabular data manipulation (DataFrames)\n",
    "import numpy as np  # Numerical operations\n",
    "import xarray as xr  # Multi-dimensional labeled arrays (NetCDF, climate, satellite)\n",
    "import dask.array as da  # Parallel computation on large arrays\n",
    "import dask  # Dask task scheduling and delayed execution\n",
    "from dask.diagnostics import ProgressBar  # Progress bar for Dask computations\n",
    "\n",
    "# --- Plotting libraries ---\n",
    "import matplotlib.pyplot as plt  # Core plotting API\n",
    "from matplotlib.dates import MonthLocator, DateFormatter  # Date-based x-axis formatting\n",
    "from matplotlib.cm import get_cmap  # Access to colormaps for styling plots\n",
    "\n",
    "# --- Utilities ---\n",
    "from tqdm import tqdm  # Progress bars for loops\n",
    "from pathlib import Path  # Object-oriented filesystem paths\n",
    "import re  # Regular expressions for string parsing and pattern matching\n",
    "from loguru import logger  # Simple, colorful logging\n",
    "import sys  # For configuring logging output\n",
    "\n",
    "# Set up the logger to show clean messages (colored text, no background)\n",
    "from helpers import configure_logger\n",
    "configure_logger()\n",
    "\n",
    "# Check that everything was imported successfully\n",
    "logger.success(\"üéâ Libraries successfully imported.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff61ccab-759f-444d-b700-50cde5809874",
   "metadata": {},
   "source": [
    "## üåä **2. Load Ocean Vector (GOaS)**\n",
    "\n",
    "Before proceeding, please download the **Global Oceans and Seas (GOaS)** dataset from the following link:  \n",
    "   [Download GOaS_v1_20211214_gpkg.zip](https://www.marineregions.org/download_file.php?name=GOaS_v1_20211214_gpkg.zip)\n",
    "\n",
    "   Once downloaded, **extract** the ZIP file and point to the `.gpkg` file in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1815800-b7a1-4122-812d-3abd86aebb72",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # Replace with the path to your downloaded GOaS dataset\n",
    "    goas_vector = gpd.read_file(\"path/to/your/downloaded/GOaS_v1_20211214_gpkg/goas_v01.gpkg\")\n",
    "    logger.success(\"üéâ GOaS dataset successfully loaded into GeoDataFrame.\")\n",
    "except Exception as e:\n",
    "    logger.error(f\"üö© Failed to load GOaS dataset: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1285f24-6234-4582-b117-cd43fd3c8bb7",
   "metadata": {},
   "source": [
    "### 2.1: Filter Ocean Vector\n",
    "In this step, we apply a **filter** to the `goas_vector` **GeoDataFrame** to select features that match the **\"North Atlantic Ocean\"** in the `\"name\"` column.\n",
    "\n",
    "- **Setting the Filter**: We define the `filter_name` variable as `\"North Atlantic Ocean\"`, which will be used to filter the `goas_vector` dataset.\n",
    "  \n",
    "- **Filtering**: We use `str.contains()` with the filter string to **select** only those rows where the `\"name\"` column contains the filter value, ensuring case-insensitivity and excluding `NaN` values.\n",
    "\n",
    "This ensures that only relevant features (those matching \"North Atlantic Ocean\") are retained for further processing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a70b662-9072-4c4a-a942-5a6b8436dbf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # Set the filter for \"North Atlantic Ocean\"\n",
    "    filter_name = \"North Atlantic Ocean\"\n",
    "\n",
    "    logger.info(f\"Filtering GOaS vector for 'name' matching '{filter_name}'\")\n",
    "    goas_vector = goas_vector[goas_vector[\"name\"].str.contains(filter_name, case=False, na=False)]\n",
    "\n",
    "    if goas_vector.empty:\n",
    "        logger.warning(f\"‚ö†Ô∏è No features found matching 'name' with '{filter_name}'. Exiting.\")\n",
    "        raise ValueError(f\"No features found for {filter_name}.\")\n",
    "    else:\n",
    "        logger.success(f\"üéâ Successfully filtered GOaS vector for 'name' matching '{filter_name}'.\")\n",
    "\n",
    "except Exception as filter_error:\n",
    "    logger.error(f\"üö© Filtering error: {filter_error}\")\n",
    "    raise filter_error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "811ceba1-9c4a-45a7-a894-cee68cbc9b3d",
   "metadata": {},
   "source": [
    "## üó∫Ô∏è **3. Load Latitude Bands**\n",
    "\n",
    "Next, we load the **latitude bands** that we created in \"[01_create_latitude_blocks](01_create_latitude_blocks.ipynb)\" to clip the ocean vector. These latitude bands will help us analyze one section of the ocean at a time, as different latitudes experience phytoplankton blooms at different times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dad6c8b6-d906-4540-b172-35139142c8fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # Replace with the path to the latitude bands GeoJSON file\n",
    "    clip_vector = gpd.read_file(Path.cwd()/\"data/latitude_bands_global.geojson\")\n",
    "    \n",
    "    logger.success(\"üéâ Latitude bands successfully loaded into GeoDataFrame.\")\n",
    "except Exception as e:\n",
    "    logger.error(f\"üö© Failed to load latitude bands: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cbff859-56af-44af-94db-6da8ad9ef9d8",
   "metadata": {},
   "source": [
    "## ‚úÇÔ∏è **4. Clip Ocean by Latitude**\n",
    "\n",
    "This step performs the clipping of the **GOaS vector** by each latitude band. For each latitude band:\n",
    "\n",
    "- We clean the **band label** to make it a valid filename by removing special characters and replacing spaces with underscores.\n",
    "- We use **GeoPandas‚Äô `clip` function** to clip the ocean data based on the latitude band‚Äôs geometry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d79330de-f903-403f-91c5-b21dbf6466b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    all_clipped_geometries = []  # List to store clipped geometries\n",
    "    band_labels = []  # List to store corresponding band labels\n",
    "    \n",
    "    # Iterate through each latitude band and clip\n",
    "    for _, row in clip_vector.iterrows():\n",
    "        clip_geom = row.geometry\n",
    "        band_label = row[\"Latitude_Range\"]\n",
    "\n",
    "        # Clean the band label: Replace spaces with \"_\", slashes with \"-\", and remove degree signs\n",
    "        band_label = re.sub(r\"[¬∞]\", \"\", band_label)  # Remove degree signs\n",
    "        band_label = band_label.replace(\" \", \"_\").replace(\"/\", \"-\")\n",
    "\n",
    "        logger.info(f\"Clipping for latitude range {band_label}...\")\n",
    "\n",
    "        # Use GeoPandas `clip` function to clip the GOaS vector by the latitude band geometry\n",
    "        clipped_gdf = gpd.clip(goas_vector, clip_geom)\n",
    "\n",
    "        # Add to the list if not empty\n",
    "        if not clipped_gdf.empty:\n",
    "            all_clipped_geometries.append(clipped_gdf)  # Collect clipped data\n",
    "            band_labels.append(band_label)  # Collect the corresponding band label\n",
    "            logger.success(f\"üéâ Clipped data for {band_label} added.\")\n",
    "        else:\n",
    "            logger.warning(f\"‚ö†Ô∏è No features found for latitude range {band_label}. This could be due to {filter_name} not occurring in this latitude range. Skipping.\")\n",
    "\n",
    "    # Combine all clipped geometries into a single GeoDataFrame\n",
    "    if all_clipped_geometries:\n",
    "        clipped_gdf = gpd.GeoDataFrame(pd.concat(all_clipped_geometries, ignore_index=True))\n",
    "        clipped_gdf['Latitude_Range'] = band_labels  # Add latitude band labels to the combined GeoDataFrame\n",
    "\n",
    "        # Log a success message with some stats\n",
    "        logger.success(\n",
    "            f\"üéâ Successfully clipped {len(all_clipped_geometries)} latitude bands \"\n",
    "            f\"with a total of {len(clipped_gdf)} features.\"\n",
    "        )\n",
    "    else:\n",
    "        logger.warning(\"‚ö†Ô∏è No features were clipped. No file created.\")\n",
    "except Exception as e:\n",
    "    logger.error(f\"üö© Error during the clipping process: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8238d46-cc80-42d3-b77c-e32180669496",
   "metadata": {},
   "source": [
    "## üìà **5. Extract Chlorophyll Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e67403af-41d5-4fce-a96c-e542c183cf18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# File paths\n",
    "netcdf_file = \"replace_with_path/cmems_mod_glo_bgc-pft_anfc_0.25deg_P1D-m_chl_90.00W-30.00E_80.00S-90.00N_0.49m_2024-01-01-2025-01-01.nc\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b13ee5b8-ec24-461e-8aec-88d3bf14d67b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the NetCDF file with Dask for chunked processing\n",
    "ds = xr.open_dataset(netcdf_file, chunks={'time': 1, 'lat': 100, 'lon': 100})  # Adjust chunk sizes based on your data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f61590-cb01-4428-97ef-e35ac581053c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea3ff987-01f8-44d7-82ba-027d65ccd1ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "chlorophyll_var = \"chl\"  # Adjust if variable name is different\n",
    "\n",
    "# Extract time steps\n",
    "time_steps = ds.time.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46ec70b2-f7d0-4c1e-8e49-fd110d566630",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare to store results\n",
    "results = []\n",
    "\n",
    "try:\n",
    "    # Loop through each latitude band geometry\n",
    "    for _, row in clipped_gdf.iterrows():\n",
    "        band_geometry = row.geometry\n",
    "        band_label = row[\"Latitude_Range\"]\n",
    "\n",
    "        logger.info(f\"Processing latitude range {band_label}...\")\n",
    "\n",
    "        # Create a list to hold all delayed operations for this band\n",
    "        delayed_tasks = []\n",
    "\n",
    "        # Define the full processing pipeline as delayed operations\n",
    "        for time in time_steps:\n",
    "            def process_time_step(time_step, geometry, crs):\n",
    "                # Select time and first depth level\n",
    "                da = ds[chlorophyll_var].sel(time=time_step).isel(depth=0)\n",
    "            \n",
    "                # Set spatial reference\n",
    "                da.rio.set_spatial_dims(x_dim=\"longitude\", y_dim=\"latitude\", inplace=True)\n",
    "                da.rio.write_crs(\"EPSG:4326\", inplace=True)\n",
    "            \n",
    "                # Clip and compute mean\n",
    "                masked_raster = da.rio.clip([geometry], crs, drop=True, all_touched=True)\n",
    "                return float(masked_raster.mean().compute())\n",
    "\n",
    "\n",
    "            # Create a delayed task for the entire processing pipeline\n",
    "            delayed_task = dask.delayed(process_time_step)(time, band_geometry, clipped_gdf.crs)\n",
    "            delayed_tasks.append(delayed_task)\n",
    "\n",
    "        # Compute all tasks for this latitude band with a single progress bar\n",
    "        with ProgressBar():\n",
    "            masked = dask.compute(*delayed_tasks)\n",
    "\n",
    "        # Store results for the current latitude band\n",
    "        results.append({\"Latitude_Range\": band_label, \"chlorophyll_mean\": list(masked)})\n",
    "\n",
    "    # Log success after all latitude bands have been processed\n",
    "    logger.success(f\"üéâ Successfully processed all {len(clipped_gdf)} latitude bands!\")\n",
    "\n",
    "except Exception as e:\n",
    "    logger.error(f\"üö© Error during processing: {str(e)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1caaa989-406b-4a16-be7a-0240a4709db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert results to a DataFrame of latitude bands with their daily mean chlorophyll values\n",
    "chlorophyll_data = pd.DataFrame({\n",
    "    row[\"Latitude_Range\"]: row[\"chlorophyll_mean\"]\n",
    "    for row in results\n",
    "})\n",
    "\n",
    "# Set index to dates (formatted as DD.MM.YY)\n",
    "chlorophyll_data.index = pd.to_datetime(time_steps).strftime(\"%d.%m.%y\")\n",
    "\n",
    "# Reset index to turn dates into a column\n",
    "chlorophyll_data.reset_index(inplace=True)\n",
    "chlorophyll_data.rename(columns={\"index\": \"date\"}, inplace=True)\n",
    "\n",
    "# Save to CSV\n",
    "output_file = Path.cwd() / \"data/chlorophyll_mean_timeseries_by_lat_band.csv\"\n",
    "chlorophyll_data.to_csv(output_file, index=False)\n",
    "\n",
    "logger.success(f\"üéâ CSV saved in desired format: {output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90bdbb2a-9e72-4bd3-acb6-90f63edf49c7",
   "metadata": {},
   "source": [
    "## üìä **6. Visualize time-series**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6a99975-3d3c-42c7-833b-39644fdba8fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a colormap that can generate N colors\n",
    "num_lines = len(chlorophyll_data.columns) - 1  # exclude date\n",
    "cmap = get_cmap(\"Set2\", num_lines)  # or \"Set2\", \"tab10\", etc.\n",
    "\n",
    "# --- Plot setup ---\n",
    "fig, ax = plt.subplots(figsize=(14, 7))\n",
    "\n",
    "# Add light grey background for spring bloom\n",
    "ax.axvspan(pd.Timestamp(\"2024-03-01\"), pd.Timestamp(\"2024-06-30\"), color=\"white\", alpha=0.3)\n",
    "\n",
    "# Plot each latitude band\n",
    "for i, column in enumerate(chlorophyll_data.columns[1:]):\n",
    "    ax.plot(\n",
    "        chlorophyll_data[\"date\"],\n",
    "        chlorophyll_data[column],\n",
    "        label=column.replace(\"_\", \" \") + \"¬∞N\",\n",
    "        linewidth=2,\n",
    "        color=cmap(i)\n",
    "    )\n",
    "\n",
    "# Title & subtitle\n",
    "plt.suptitle(\"2024 Chlorophyll-a concentration in the North Atlantic\", fontsize=18, fontweight=\"bold\", x=0.01, ha='left')\n",
    "plt.title(\"Average daily chlorophyll-a concentration by 10¬∞ latitude block\", fontsize=12, loc='left')\n",
    "\n",
    "# X-axis formatting\n",
    "ax.xaxis.set_major_locator(MonthLocator())\n",
    "ax.xaxis.set_major_formatter(DateFormatter('%b'))\n",
    "\n",
    "# Clean up\n",
    "ax.set_ylim(0, 1.5)\n",
    "ax.legend(title=\"\", loc=\"upper left\", fontsize=10)\n",
    "ax.tick_params(axis='both', labelsize=10)\n",
    "ax.grid(False)\n",
    "for spine in [\"top\", \"right\"]:\n",
    "    ax.spines[spine].set_visible(False)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (3.10)",
   "language": "python",
   "name": "3.10"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
